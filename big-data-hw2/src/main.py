import os
import math
import hashlib

DOCUMENTS_COUNT = 436
DEFAULT_K = 9
ALPHABET_SIZE = 30  # it's better be odd
SIGNATURE_SIZE = 50  # make it dividable to BAND_SIZE
BAND_SIZE = 5
SIMILARITY_THRESHOLD = 0.5


def load_documents():
    """
    loads documents and returns them as a list
    :return: list of documents
    """
    documents = []
    for i in range(1, DOCUMENTS_COUNT + 1):
        file_path = os.path.join(
            os.path.abspath(os.path.dirname(__file__)), '../data/{0}'.format(i)
        )
        with open(file_path, 'r') as fp:
            document = fp.read()
            documents.append(document)

    return documents


def preprocess_document(document):
    """
    this function will remove redundant blanks, and some other characters from document
    :param document:
    :return: a processed document as string
    """
    processed_document = ''

    # string concatenation is an expensive operation so instead of concatenating character by character, we concatenate
    # bulk of document from the last known invalid character to the current known invalid character
    window_start = 0
    window_end = 0
    for c in document:
        if c in [' ', ',', ':', ';', '.', '\n', '\t']:
            # an invalid character found, we add the content before it and shift the window
            processed_document += document[window_start:window_end].upper()
            window_start = window_end = window_end + 1
            continue

        window_end += 1

    # add the remaining document to processed document
    processed_document += document[window_start:window_end].upper()
    return processed_document


def generate_shingles(k, processed_document):
    """
    generates k-shingles from a processed document
    :param processed_document:
    :param k:
    :return:
    """
    shingles = []

    # we will use a window with length of k, so that the content between window start and window end will be a shingle
    # we will shift this window to the right 1 by 1
    for window_end in range(k, len(processed_document) + 1):
        window_start = window_end - k
        # the shingle is generated by cutting document from window_start to window_end
        shingles.append(processed_document[window_start:window_end])

    return shingles


def hash_shingle(k, shingle):
    """
    in this function we transform input k-shingle to a unique integer.
    for example with k=3, "aba" = 0 + 30 + 0.
    """
    hashed_value = 0

    i = k - 1
    for c in shingle:
        # as 'A' ascii code is 49 we subtract it from each characters ascii code to get zero based values
        c_code = ord(c) - 49
        hashed_value += (ALPHABET_SIZE ** i) * c_code
        i -= 1

    return hashed_value


def generate_shingle_matrix(k, all_shingles):
    """
    generates a matrix that indicates which document has which shingles
    :param all_shingles: list of list of shingles 
    :return: matrix
    """

    # we will be saving the matrix as sparse, so that each row represents one documents shingles
    # the shingles in the matrix are hashed before being saved to take less memory
    matrix = []
    for shingles in all_shingles:
        # we create a row for each document in the matrix
        row = []
        for shingle in shingles:
            row.append(hash_shingle(k, shingle))
        matrix.append(row)
    return matrix


def generate_permutation_function(k, seed):
    """
    this function returns a hash function which virtually creates a permutation of a matrix
    :param seed: it should be higher than zero
    :return: hash function
    """
    mod_argument = (ALPHABET_SIZE ** k) + 1

    def permutation_function(position):
        # this function works with following formula: new_position = s*oldposition mod numberofrows
        return (seed * position) % mod_argument

    return permutation_function


def minhash(document_column, permutation_function):
    """
    gets minhash value for the input document_column (a row in shingle matrix) 
    :param document_column: each row in the our view matrix actually shows a column in the shingle/document matrix
    :param permutation_function: a function that transforms positions to their respective new positions
    :return: minhash
    """
    # at first we set minhash_value as infinity, because we want to find the minimum value in the list
    minhash_value = math.inf
    # as we hashed shingles, each value in document_column shows both shingle value and position with one int
    for position in document_column:
        permuted_position = permutation_function(position)
        if permuted_position < minhash_value:
            minhash_value = permuted_position

    return minhash_value


def generate_minhash_signature(k, document_column, rounds):
    """
    generates and returns minhash signature for a specific document, the length of the signature is
    equal to the input rounds argument
    """
    signature = []
    # we generate a permutation function for each round and compute the minhash with that specific permutation
    for i in range(rounds):
        permutation_function = generate_permutation_function(k, i + 1)
        minhash_value = minhash(document_column, permutation_function)
        signature.append(minhash_value)

    return signature


def generate_minhash_matrix(k, matrix, rounds):
    """
    generates minhash signature matrix from the input shingle matrix
    """
    minhash_matrix = []

    # we simply call signature creation function for each document
    for document_column in matrix:
        signature = generate_minhash_signature(k, document_column, rounds)
        minhash_matrix.append(signature)

    return minhash_matrix


def generate_lsh_function(seed):
    """
    this function returns a lsh function which turns the input signature to X bands, and each lsh
    compares a specific band according to the seed. these functions return similar values only if
    the bands are equal
    """
    band_start = seed * BAND_SIZE
    band_end = band_start + BAND_SIZE

    def lsh_function(signature):
        val = ''
        for i in range(band_start, band_end):
            val += ',' + str(signature[i])

        return hash(val)

    return lsh_function


def generate_candidate_pairs(minhash_matrix):
    """
    computes lsh functions for each band on all document minhash signatures and then
    if two documents are similar in at least one lsh function, they will be added to
    candidate pairs array
    """
    candidate_pairs = set()

    bands_count = int(SIGNATURE_SIZE / BAND_SIZE)
    for i in range(bands_count):
        # documents with similar lsh value will go into the same key of this dictionary
        locality_array = {}
        lsh_function = generate_lsh_function(i)
        # call lsh_function for all signatures of minhash_matrix
        for dn, signature in enumerate(minhash_matrix):
            h = lsh_function(signature)
            if h in locality_array:
                locality_array[h].append(dn)
            else:
                locality_array[h] = [dn]

        # find keys with more than 1 item in it to generate candidate pair
        for key in locality_array:
            for j in range(len(locality_array[key])):
                for k in range(j + 1, len(locality_array[key])):
                    candidate_pairs.add(
                        (locality_array[key][j], locality_array[key][k]))

    return candidate_pairs


def get_candidate_pairs_similarity(minhash_matrix, candidate_pair):
    """
    computes similarity of two documents using their minhash signatures
    """
    found = 0
    for minhash in minhash_matrix[candidate_pair[0]]:
        if minhash in minhash_matrix[candidate_pair[1]]:
            found += 1

    return found / SIGNATURE_SIZE


if __name__ == '__main__':
    print('loading documents ...')
    documents = load_documents()

    print('preprocessing ...')
    processed_documents = []
    for document in documents:
        processed_document = preprocess_document(document)
        processed_documents.append(processed_document)
    del documents

    print('converting all documents to shingles ...')
    all_shingles = []
    for processed_document in processed_documents:
        shingles = generate_shingles(DEFAULT_K, processed_document)
        all_shingles.append(shingles)
    del processed_documents

    print('generating matrix ...')
    matrix = generate_shingle_matrix(DEFAULT_K, all_shingles)
    del all_shingles

    print('generating minhash matrix ...')
    minhash_matrix = generate_minhash_matrix(
        DEFAULT_K, matrix, SIGNATURE_SIZE)

    print('finding candidate pairs ...')
    candidate_pairs = generate_candidate_pairs(minhash_matrix)

    for pair in candidate_pairs:
        similarity = get_candidate_pairs_similarity(minhash_matrix, pair)
        # only show items with similarity higher than the threshold
        if similarity >= SIMILARITY_THRESHOLD:
            print('{0}: {1}'.format(
                pair, get_candidate_pairs_similarity(minhash_matrix, pair)))
